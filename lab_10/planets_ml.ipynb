{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing out-of-this world data, Part 2\n",
    "Using data collected from the Open Exoplanet Catalogue database: https://github.com/OpenExoplanetCatalogue/open_exoplanet_catalogue/\n",
    "\n",
    "## Data License\n",
    "Copyright (C) 2012 Hanno Rein\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this database and associated scripts (the \"Database\"), to deal in the Database without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Database, and to permit persons to whom the Database is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Database. A reference to the Database shall be included in all scientific publications that make use of the Database.\n",
    "\n",
    "THE DATABASE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE DATABASE OR THE USE OR OTHER DEALINGS IN THE DATABASE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "planets = pd.read_csv('data/planets.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we completed our EDA in the [`planets_ml.ipynb`](../lab_09/planets_ml.ipynb) notebook for last chapter, we will just look at the first 5 rows to refresh our memory of the data rather than repeating the EDA here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "As in chapter 9, we will be predicting the length of a year (period) on our planets data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = planets[\n",
    "    ['semimajoraxis', 'period', 'mass', 'eccentricity']\n",
    "].dropna()\n",
    "planets_X = data[['semimajoraxis', 'mass', 'eccentricity']]\n",
    "planets_y = data.period\n",
    "\n",
    "pl_X_train, pl_X_test, pl_y_train, pl_y_test = train_test_split(\n",
    "    planets_X, planets_y, test_size=0.25, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression to Predict Year Length from Lab 9\n",
    "This was the result from chapter 9 for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lm = LinearRegression().fit(pl_X_train, pl_y_train)\n",
    "preds = lm.predict(pl_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean absolute error (MAE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(pl_y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with `GridSearchCV`\n",
    "Note that `GridSearchCV` will try to maximize the scores, but we are using error metrics for all but $R^2$, so we use the versions marked with `neg_` as a prefix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model_pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('lr', LinearRegression())\n",
    "])\n",
    "\n",
    "search_space = {\n",
    "    'scale__with_mean': [True, False], \n",
    "    'scale__with_std': [True, False],\n",
    "    'lr__fit_intercept': [True, False], \n",
    "    'lr__normalize': [True, False]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    model_pipeline, search_space, cv=5,\n",
    "    scoring={\n",
    "        'r_squared': 'r2', \n",
    "        'mse': 'neg_mean_squared_error', \n",
    "        'mae': 'neg_mean_absolute_error',\n",
    "        'rmse': make_scorer(lambda x, y: -np.sqrt(mean_squared_error(x, y)))\n",
    "    }, refit='mae'\n",
    ").fit(pl_X_train, pl_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the best score from the cross validation and the best hyperparameters in the search space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters (CV score=%.2f):\\n%s' % (\n",
    "    grid.best_score_, grid.best_params_\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reduced our MAE by over 120 Earth days (compared to chapter 9's model):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(pl_y_test, grid.predict(pl_X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can a decision tree tell us what features are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=0).fit(pl_X_train, pl_y_train)\n",
    "[(col, coef) for col, coef in zip(\n",
    "    pl_X_train.columns, dt.feature_importances_\n",
    ")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the decisions the tree is making:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "graphviz.Source(export_graphviz(\n",
    "    DecisionTreeRegressor(\n",
    "        max_depth=4, random_state=0\n",
    "    ).fit(pl_X_train, pl_y_train),\n",
    "    feature_names=pl_X_train.columns\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "Ridge (L2) and LASSO (L1) are terms we can add to regression to penalize large coefficients. L2 uses squared coefficients and L1 uses the absolute value. LASSO tends to drive coeffiecients to zero and is therefore used for feature selection. We can combine the two in an elastic net. These help to reduce overfitting. Check the documentation for parameters that can be tuned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "\n",
    "ridge, lasso, elastic = Ridge(), Lasso(), ElasticNet()\n",
    "\n",
    "for model in [ridge, lasso, elastic]:\n",
    "    model.fit(pl_X_train, pl_y_train)\n",
    "    print(\n",
    "        f'{model.__class__.__name__}: '\n",
    "        f'{model.score(pl_X_test, pl_y_test):.4}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div style=\"overflow: hidden; margin-bottom: 10px;\">\n",
    "    <div style=\"float: left;\">\n",
    "        <a href=\"../../lab_09/planets_ml.ipynb\">\n",
    "            <button>&#8592; Lab 9</button>\n",
    "        </a>\n",
    "        <a href=\"./red_wine.ipynb\">\n",
    "            <button>Red Wine</button>\n",
    "        </a>\n",
    "        <a href=\"./wine.ipynb\">\n",
    "            <button>Red + White Wine</button>\n",
    "        </a>\n",
    "    </div>\n",
    "    <div style=\"float: right;\">\n",
    "        <a href=\"../solutions/lab_10/exercise_1.ipynb\">\n",
    "            <button>Solutions</button>\n",
    "        </a>\n",
    "        <a href=\"../lab_11/1-EDA_unlabeled_data.ipynb\">\n",
    "            <button>Lab 11 &#8594;</button>\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
