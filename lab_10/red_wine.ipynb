{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Red Wine Quality, Part 2\n",
    "Data from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "\n",
    "## Citations\n",
    "<pre>\n",
    "Dua, D. and Karra Taniskidou, E. (2017). \n",
    "UCI Machine Learning Repository [http://archive.ics.uci.edu/ml/index.php]. \n",
    "Irvine, CA: University of California, School of Information and Computer Science.\n",
    "</pre>\n",
    "\n",
    "<pre>\n",
    "P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "Modeling wine preferences by data mining from physicochemical properties.\n",
    "In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n",
    "</pre>\n",
    "\n",
    "Available at:\n",
    "- [@Elsevier](http://dx.doi.org/10.1016/j.dss.2009.05.016)\n",
    "- [Pre-press (pdf)](http://www3.dsi.uminho.pt/pcortez/winequality09.pdf)\n",
    "- [bib](http://www3.dsi.uminho.pt/pcortez/dss09.bib)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "red_wine = pd.read_csv('data/winequality-red.csv')\n",
    "red_wine['high_quality'] = pd.cut(red_wine.quality, bins=[0, 6, 10], labels=[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we completed our EDA in the [`red_wine.ipynb`](../lab_09/red_wine.ipynb) notebook for last chapter, we will just look at the first 5 rows to refresh our memory of the data rather than repeating the EDA here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "As in chapter 9, we will try to predict which red wines will be high-quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "red_y = red_wine.pop('high_quality')\n",
    "red_X = red_wine.drop(columns='quality')\n",
    "\n",
    "r_X_train, r_X_test, r_y_train, r_y_test = train_test_split(\n",
    "    red_X, red_y, test_size=0.1, random_state=0, stratify=red_y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification of Red Wine Quality from Chapter 9\n",
    "This was the result from chapter 9 for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "red_quality_lr = Pipeline([\n",
    "    ('scale', StandardScaler()), \n",
    "    ('lr', LogisticRegression(\n",
    "        class_weight='balanced', random_state=0\n",
    "    ))\n",
    "]).fit(r_X_train, r_y_train)\n",
    "\n",
    "quality_preds = red_quality_lr.predict(r_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model needs some tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(r_y_test, quality_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import plot_roc\n",
    "\n",
    "plot_roc(r_y_test, red_quality_lr.predict_proba(r_X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import confusion_matrix_visual\n",
    "\n",
    "confusion_matrix_visual(r_y_test, quality_preds, ['low', 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for the Best Hyperparameters with Plots\n",
    "We have been working with training and testing sets; however, in order to try out different hyperparameters, we need a third set: the validation set. We will train with the training set as usual. The validation set will be used to test different hyperparameters. Only after we have our model tuned will we test with the testing set. Note that the validation set is not the testing set, nor should they contain the same data. \n",
    "\n",
    "One way of making the validation set would be to run `train_test_split()` on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "r_X_train_new, r_X_validate, r_y_train_new, r_y_validate = train_test_split(\n",
    "    r_X_train, r_y_train, test_size=0.3, random_state=0, stratify=r_y_train\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`C` is the inverse of the regularization strength. It determines the weight on the penalty term. We will try 10 values from $10^{-1}$ to $10^1$ for `C`. To make this range of numbers, we use `np.logspace()` and provide the exponents (-1 and 1) of the minimum and maximum values in the range. We then get evenly-spaced values in between:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "inv_regularization_strengths = np.logspace(-1, 1, num=10)\n",
    "scores = []\n",
    "\n",
    "for inv_reg_strength in inv_regularization_strengths:\n",
    "    pipeline = Pipeline([\n",
    "        ('scale', MinMaxScaler()),\n",
    "        ('lr', LogisticRegression(\n",
    "            class_weight='balanced', random_state=0,\n",
    "            C=inv_reg_strength\n",
    "        ))\n",
    "    ]).fit(r_X_train_new, r_y_train_new)\n",
    "    scores.append(\n",
    "        f1_score(pipeline.predict(r_X_validate), r_y_validate)\n",
    "    )\n",
    "\n",
    "plt.plot(inv_regularization_strengths, scores, 'o-')\n",
    "plt.xscale('log')\n",
    "plt.xlabel('inverse of regularization strength (C)')\n",
    "plt.ylabel(r'$F_1$ score')\n",
    "plt.title(r'$F_1$ score vs. Inverse of Regularization Strength')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for the Best Hyperparameters with `GridSearchCV`\n",
    "We can specify a search space as a dictionary of parameter names and values to try for each. Note that if we have any preprocessing steps, we must use a pipeline. We can tune hyperparameters in a pipeline if we prefix the hyperparameter name with the step's name followed by `__`. We can specify the metric to use for the tuning as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('lr', LogisticRegression(\n",
    "        class_weight='balanced', random_state=0\n",
    "    ))\n",
    "])\n",
    "\n",
    "search_space = {\n",
    "    'lr__C': np.logspace(-1, 1, num=10),\n",
    "    'lr__fit_intercept': [True, False]\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    pipeline, search_space, scoring='f1_macro', cv=5\n",
    ").fit(r_X_train, r_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `best_params_` attribute to see the best parameters from the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `best_score_` shows the score for the specified metric that was achieved on the validation set using the best parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using the testing set, we can see that our $F_1$ score is now higher than what we got without hyperparameter tuning in chapter 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(r_y_test, lr_grid.predict(r_X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GridSearchCV` with CV Object\n",
    "We can specify the number of folds to use for cross validation and even change the method of doing so with the `cv` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    pipeline, search_space, scoring='f1_macro',\n",
    "    cv=RepeatedStratifiedKFold(random_state=0)\n",
    ").fit(r_X_train, r_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this is different from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best parameters (CV score=%.2f):\\n    %s' % (\n",
    "    lr_grid.best_score_, lr_grid.best_params_\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial features and interaction terms\n",
    "We can look at a pairplot to try and find any non-linear relationships between the features in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(r_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we suspect there is a non-linear relationship between our variables, we can add polynomial features to our model to generalize our linear model. The `PolynomialFeatures` class from scikit-learn will transform our input data into a bias term (1), a term for each of the variables as found in the starting data, a term for each combination of 2 variables multiplied together, and a term for the square of each variable (this can be modified to include higher powers with the `degree` parameter):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "PolynomialFeatures(degree=2).fit_transform(r_X_train[['citric acid', 'fixed acidity']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a breakdown of the first row in the previous result to help understand where the numbers came from:\n",
    "\n",
    "| term | $bias$ | $citric\\ acid$ | $fixed\\ acidity$ | $citric\\ acid^2$ | $citric\\ acid \\times fixed\\ acidity$ | $fixed\\ acidity^2$ |\n",
    "|:---: | :---: | :---: | :---: | :---: | :---: | :---: |\n",
    "| **value** | 1.000e+00 | 5.500e-01 | 9.900e+00 | 3.025e-01 | 5.445e+00 | 9.801e+01 |\n",
    "\n",
    "Note we can also specify to not include the bias (`include_bias=False`) and to only give interaction terms (`interaction_only=True`). This leaves us with the value for each of the variables and their interaction term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "PolynomialFeatures(\n",
    "    degree=2, include_bias=False, interaction_only=True\n",
    ").fit_transform(r_X_train[['citric acid', 'fixed acidity']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put this in a pipeline to build our model with these features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('scale', MinMaxScaler()),\n",
    "    ('lr', LogisticRegression(\n",
    "        class_weight='balanced', random_state=0\n",
    "    ))\n",
    "]).fit(r_X_train, r_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the performance is slightly better than it was before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = pipeline.predict(r_X_test)\n",
    "print(classification_report(r_y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Unions\n",
    "We can combine multiple preprocessing transformations on our data with the feature union:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    ('variance', VarianceThreshold(threshold=0.01)),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False, interaction_only=True))\n",
    "])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('normalize', MinMaxScaler()),\n",
    "    ('feature_union', combined_features),\n",
    "    ('lr', LogisticRegression(\n",
    "        class_weight='balanced', random_state=0\n",
    "    ))\n",
    "]).fit(r_X_train, r_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the feature union (first 9 are from `VarianceThreshold`, rest are interaction terms):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.named_steps['feature_union'].transform(r_X_train)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This also results in marginal improvements in recall in $F_1$ score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "preds = pipeline.predict(r_X_test)\n",
    "print(classification_report(r_y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import plot_pr_curve\n",
    "plot_pr_curve(r_y_test, pipeline.predict_proba(r_X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import confusion_matrix_visual\n",
    "confusion_matrix_visual(r_y_test, preds, ['low', 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble methods\n",
    "Ensemble methods combine many models (often weak ones) to create another (stronger one) that will either minimize average error between actual and predicted (the bias) or improve how well it generalizes to unseen data (minimize the variance). We have to strike a balance between complex models that may increase variance, as they tend to overfit, with simple models that may have high bias, as they tend to underfit. This is called the bias-variance trade-off, which is illustrated in the following subplots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_aids.ml_viz import bias_variance_tradeoff\n",
    "bias_variance_tradeoff()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Method: Random Forest\n",
    "A random forest is a bagging technique (bootstrap aggregation), where we build many decision trees that each get a different bootstrapped sample of the data. At the end, this is aggregated by voting for classification and averaging for regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "search_space = {\n",
    "    'max_depth': [4, 8],\n",
    "    'min_samples_leaf': [4, 6]\n",
    "}\n",
    "\n",
    "rf_grid = GridSearchCV(\n",
    "    rf, search_space, cv=5, scoring='precision'\n",
    ").fit(r_X_train, r_y_train)\n",
    "\n",
    "rf_preds = rf_grid.predict(r_X_test)\n",
    "rf_grid.score(r_X_test, r_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Method: Gradient Boosted Trees\n",
    "This is a boosting technique, meaning many weak learners are trained, but each learns from the mistakes of the others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "search_space = {\n",
    "    'max_depth': [4, 8],\n",
    "    'min_samples_leaf': [4, 6],\n",
    "    'learning_rate': [0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "gb_grid = GridSearchCV(\n",
    "    gb, search_space, cv=5, scoring='f1_macro'\n",
    ").fit(r_X_train, r_y_train)\n",
    "\n",
    "gb_preds = gb_grid.predict(r_X_test)\n",
    "gb_grid.score(r_X_test, r_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting\n",
    "We can combine various models with voting. Often it will be interesting to first check their level of agreement with Cohen's Kappa score. Let's check the agreement between the gradient boosting classifier and the random forest range. This metric has a range of [-1, 1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "cohen_kappa_score(\n",
    "    rf_grid.predict(r_X_test), gb_grid.predict(r_X_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to conduct voting:\n",
    "- majority rules (hard)\n",
    "- highest probability (soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "majority_rules = VotingClassifier(\n",
    "    [('lr', lr_grid.best_estimator_), ('rf', rf_grid.best_estimator_), ('gb', gb_grid.best_estimator_)],\n",
    "    voting='hard'\n",
    ").fit(r_X_train, r_y_train)\n",
    "\n",
    "max_probabilities = VotingClassifier(\n",
    "    [('lr', lr_grid.best_estimator_), ('rf', rf_grid.best_estimator_), ('gb', gb_grid.best_estimator_)],\n",
    "    voting='soft'\n",
    ").fit(r_X_train, r_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agreement between majority rules and max probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_kappa_score(\n",
    "    majority_rules.predict(r_X_test), max_probabilities.predict(r_X_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Majority Rules Evaluation\n",
    "\n",
    "This is our best model yet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(r_y_test, majority_rules.predict(r_X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Max Probabilities Evaluation\n",
    "\n",
    "This performs worse than the majority rules voting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(r_y_test, max_probabilities.predict(r_X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Imbalances\n",
    "k-NN with 5 neighbors for a baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=5\n",
    ").fit(r_X_train, r_y_train)\n",
    "\n",
    "knn_preds = knn.predict(r_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-NN trains fast because it is a **lazy learner** &mdash; calculations are made at classification time. Note times will vary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=5\n",
    ").fit(r_X_train, r_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to a support vector machine (SVM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "from sklearn.svm import SVC\n",
    "knn = SVC(gamma='auto').fit(r_X_train, r_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the performance of the baseline for reference later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(r_y_test, knn_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import plot_pr_curve\n",
    "plot_pr_curve(r_y_test, knn.predict_proba(r_X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import confusion_matrix_visual\n",
    "confusion_matrix_visual(r_y_test, knn_preds, ['low', 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random under-sampling\n",
    "We will under-sample the majority class, which will reduce the amount of training data available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "X_train_undersampled, y_train_undersampled = RandomUnderSampler(\n",
    "    random_state=0\n",
    ").fit_resample(r_X_train, r_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how few observations we started with in the minority class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_y_train.value_counts() # before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is now the number of observations in the majority class. We lost over 50% of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train_undersampled).value_counts().sort_index() # after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model is the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_undersampled = KNeighborsClassifier(\n",
    "    n_neighbors=5\n",
    ").fit(X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "knn_undersampled_preds = knn_undersampled.predict(r_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the lack of available data, this model is worse than before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(r_y_test, knn_undersampled_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import plot_pr_curve\n",
    "plot_pr_curve(r_y_test, knn_undersampled.predict_proba(r_X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import confusion_matrix_visual\n",
    "confusion_matrix_visual(r_y_test, knn_undersampled_preds, ['low', 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over-sampling with [SMOTE](https://arxiv.org/pdf/1106.1813.pdf)\n",
    "This technique will make synthetic data, so it's important to if it is a reasonable assumption to make that the data we have is representative of the full spectrum we will see and whether it will change over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "X_train_oversampled, y_train_oversampled = SMOTE(\n",
    "    random_state=0\n",
    ").fit_resample(r_X_train, r_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before, the imbalance could be observed in the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_y_train.value_counts() # before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, both classes have the same number of observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train_oversampled).value_counts().sort_index() # after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the model with the oversampled data is the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_oversampled = KNeighborsClassifier(\n",
    "    n_neighbors=5\n",
    ").fit(X_train_oversampled, y_train_oversampled)\n",
    "\n",
    "knn_oversampled_preds = knn_oversampled.predict(r_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has higher recall than the class imbalance k-NN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(r_y_test, knn_oversampled_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import plot_pr_curve\n",
    "plot_pr_curve(r_y_test, knn_oversampled.predict_proba(r_X_test)[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import confusion_matrix_visual\n",
    "confusion_matrix_visual(r_y_test, knn_oversampled_preds, ['low', 'high'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div style=\"overflow: hidden; margin-bottom: 10px;\">\n",
    "    <div style=\"float: left;\">\n",
    "        <a href=\"../../lab_09/red_wine.ipynb\">\n",
    "            <button>&#8592; Chapter 9</button>\n",
    "        </a>\n",
    "        <a href=\"./planets_ml.ipynb\">\n",
    "            <button>Planets</button>\n",
    "        </a>\n",
    "        <a href=\"./wine.ipynb\">\n",
    "            <button>Red + White Wine</button>\n",
    "        </a>\n",
    "    </div>\n",
    "    <div style=\"float: right;\">\n",
    "        <a href=\"../../solutions/lab_10/exercise_1.ipynb\">\n",
    "            <button>Solutions</button>\n",
    "        </a>\n",
    "        <a href=\"../lab_11/1-EDA_unlabeled_data.ipynb\">\n",
    "            <button>Chapter 11 &#8594;</button>\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
