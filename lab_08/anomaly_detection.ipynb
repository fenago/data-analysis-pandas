{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catching Hackers\n",
    "For this lab, we will be simulating the data we will work with using the [`login_attempt_simulator` package](https://github.com/fenago/login-attempt-simulator). The simulator needs to generate random numbers from various distributions. Here is an example of each of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from visual_aids import sim_viz\n",
    "\n",
    "_ = sim_viz.show_distributions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: the Poisson distribution is discrete while the others are continuous. We use the Poisson distribution to model arrivals (users coming to login for this example). Discrete distributions have PMFs (probability mass functions) instead of PDFs.*\n",
    "\n",
    "The `simulate.py` script can be run from the command line to run the simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 simulate.py -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will simulate November 2018 using a seed of 0 and making the user base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 simulate.py -ms 0 30 \"2018-11-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "log = pd.read_csv('logs/log.csv', index_col='datetime', parse_dates=True)\n",
    "attacks = pd.read_csv(\n",
    "    'logs/attacks.csv',\n",
    "    converters={'start': np.datetime64, 'end': np.datetime64}\n",
    ") # make start and end columns datetimes but not the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Data\n",
    "The login attempts recorded from the website look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labeled data we have to research how to detect the attackers looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `shape` to see the number of attacks and login attempts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks.shape, log.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of IP addresses were from attackers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks.source_ip.nunique() / log.source_ip.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "Can we find suspicious activity looking at hourly attempts to log in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempts over time\n",
    "log.assign(attempts=1).attempts.resample('1H').sum()\\\n",
    "    .plot(figsize=(15, 5), title='hourly attempts')\\\n",
    "    .set(xlabel='datetime', ylabel='attempts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many attempts came from each IP address?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.source_ip.value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the distribution of attempts per IP address look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "log.source_ip.value_counts().plot(kind='box', ax=axes[0]).set_ylabel('attempts')\n",
    "log.source_ip.value_counts().plot(kind='hist', bins=50, ax=axes[1]).set_xlabel('attempts')\n",
    "fig.suptitle('Attempts per IP Address')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percent of the top IP addresses are hackers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hackers = attacks.source_ip.nunique()\n",
    "log.source_ip.value_counts().index[:num_hackers]\\\n",
    "    .isin(attacks.source_ip).sum() / num_hackers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the average hourly attempts per IP address look like over the time period?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempts per ip address\n",
    "log.assign(attempts=1).groupby('source_ip').attempts\\\n",
    "    .resample('1H').sum().unstack().mean()\\\n",
    "    .plot(figsize=(15, 5), title='average hourly attempts per IP address')\\\n",
    "    .set_ylabel('average hourly attempts per IP address')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of the time was a hacker's attempt successful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log[log.source_ip.isin(attacks.source_ip)]\\\n",
    "    .success.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of the time are valid users' attempts successful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log[~log.source_ip.isin(attacks.source_ip)]\\\n",
    "    .success.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is each group failing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    index=pd.Series(\n",
    "        log.source_ip.isin(attacks.source_ip), name='is_hacker'\n",
    "    ), columns=log.failure_reason\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many times does a user try to log in per hour? Valid users don't make many mistakes with their credentials, so if the hackers make many attempts with many users, we flag it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempts per user\n",
    "log.assign(attempts=1).groupby('username').attempts\\\n",
    "    .resample('1H').sum().unstack().mean()\\\n",
    "    .plot(figsize=(15, 5), title='average hourly attempts per user')\\\n",
    "    .set_ylabel('average hourly attempts per user')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate metrics per IP address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = log.pivot_table(\n",
    "    values='success', index=log.source_ip, \n",
    "    columns=log.failure_reason.fillna('success'), \n",
    "    aggfunc='count', fill_value=0\n",
    ")\n",
    "pivot.insert(0, 'attempts', pivot.sum(axis=1))\n",
    "pivot = pivot.sort_values('attempts', ascending=False).assign(\n",
    "    success_rate=lambda x: x.success / x.attempts,\n",
    "    error_rate=lambda x: 1 - x.success_rate\n",
    ")\n",
    "pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most successful IP addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.sort_values('success_rate', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What looks out of place with the five-number summary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there IP addresses being used with many distinct usernames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.groupby('source_ip').agg(dict(username='nunique'))\\\n",
    "    .username.value_counts().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual Anomaly Detection\n",
    "We had a bimodal distribution of attempts per IP address &mdash; will we have two clusters when we plot successes vs. attempts by IP address?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.plot(\n",
    "    kind='scatter', x='attempts', y='success', \n",
    "    title='successes vs. attempts by IP address', alpha=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps we can draw a boundary between these groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pivot.plot(\n",
    "    kind='scatter', x='attempts', y='success', \n",
    "    title='successes vs. attempts by IP address', alpha=0.25\n",
    ")\n",
    "plt.axvline(125, label='sample boundary', color='red', linestyle='--')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are in the research phase, we have some labeled data, so we can see if our boundary was correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "for ax in axes:\n",
    "    sns.scatterplot(\n",
    "        y=pivot.success, x=pivot.attempts, \n",
    "        hue=pivot.assign(\n",
    "            is_hacker=lambda x: x.index.isin(attacks.source_ip)\n",
    "        ).is_hacker,\n",
    "        ax=ax, alpha=0.5\n",
    "    )\n",
    "    for spine in ['top', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "axes[1].set_xscale('log')\n",
    "plt.suptitle('successes vs. attempts by IP address')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can a box plot show us outliers corresponding to the top right cluster in the previous scatter plots?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot[['attempts', 'success']].plot(\n",
    "    kind='box', subplots=True, figsize=(10, 3),\n",
    "    title='stats per IP address'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based Anomaly Detection\n",
    "We want to find the IP addresses with excessive amounts of attempts with low success rates and those attempting to log in with more unique usernames than we would deem normal (anomalies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_ip_logs = log.assign(\n",
    "    failures=lambda x: np.invert(x.success)\n",
    ").groupby('source_ip').resample('1H').agg(\n",
    "    {'username': 'nunique', 'success': 'sum', 'failures': 'sum'}\n",
    ").assign(\n",
    "    attempts=lambda x: x.success + x.failures,\n",
    "    success_rate=lambda x: x.success / x.attempts,\n",
    "    failure_rate=lambda x: 1 - x.success_rate\n",
    ").dropna().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we will use for rule-based anomaly detection looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_ip_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percent Difference from Threshold\n",
    "A simple rule would be to check if values are a certain percentage or more different from some threshold. \n",
    "\n",
    "#### Bootstrapping\n",
    "In our case, the threshold will be an hourly baseline of login activity. We could use bootstrapping to calculate the baseline with random sample of size 10 for each hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baselines(hourly_ip_logs, func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate hourly bootstrapped statistic per column.\n",
    "    \n",
    "    Parameters:\n",
    "        - hourly_ip_logs: Data to sample from.\n",
    "        - func: Statistic to calculate.\n",
    "        - args: Additional positional arguments for `func`\n",
    "        - kwargs: Additional keyword arguments for `func`\n",
    "    \n",
    "    Returns:\n",
    "        `pandas.DataFrame` of hourly bootstrapped statistics\n",
    "    \"\"\"\n",
    "    if isinstance(func, str):\n",
    "        func = getattr(pd.DataFrame, func)\n",
    "\n",
    "    return hourly_ip_logs\\\n",
    "        .assign(hour=lambda x: x.datetime.dt.hour).groupby('hour')\\\n",
    "        .apply(\n",
    "            lambda x: x.sample(10, random_state=0, replace=True)\\\n",
    "                .pipe(func, *args, **kwargs, numeric_only=True)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we run our function, we get a bootstrapped hourly average to use as a baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = get_baselines(hourly_ip_logs, 'mean')\n",
    "averages.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique however doesn't guarantee we won't mix any of the hacker activity into our baseline calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages.nlargest(6, 'failure_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trimming\n",
    "We need to remove some of the outliers for better baselines. Let's write a function to trim values beyond a given quantile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(x, quantile):\n",
    "    \"\"\"Remove rows with entries for the username, attempts, or failure_rate columns above a given quantile.\"\"\"\n",
    "    mask = ((x.username <= x.username.quantile(quantile))\n",
    "        & (x.attempts <= x.attempts.quantile(quantile))\n",
    "        & (x.failure_rate <= x.failure_rate.quantile(quantile)))\n",
    "    return x[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function can be used when we run `apply()` after `groupby()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_hourly_logs = hourly_ip_logs\\\n",
    "    .assign(hour=lambda x: x.datetime.dt.hour)\\\n",
    "    .groupby('hour').apply(lambda x: trim(x, 0.95))\\\n",
    "    .drop(columns='hour').reset_index().iloc[:,2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our trimmed baseline doesn't have really large values anymore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "averages = get_baselines(trimmed_hourly_logs, 'mean')\n",
    "averages.iloc[[19, 23, 3, 11, 14, 16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a function to determine when our thresholds are exceeded. Our threshold will be some percentage of the baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pct_change_threshold(hourly_ip_logs, baselines, pcts=None):\n",
    "    \"\"\"\n",
    "    Return flagged IP addresses based on thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "        - hourly_ip_logs: Aggregated hourly data per IP address.\n",
    "        - baselines: Hourly baselines per column in data.\n",
    "        - pcts: Dictionary of custom percentages per column for\n",
    "                calculating upper bound thresholds (baseline * pct).\n",
    "                If not provided, pct will be 1.\n",
    "    \n",
    "    Returns:\n",
    "        `pandas.Series` containing the IP addresses flagged.\n",
    "    \"\"\"\n",
    "    pcts = {} if not pcts else pcts\n",
    "\n",
    "    return hourly_ip_logs.assign(\n",
    "        hour=lambda x: x.datetime.dt.hour\n",
    "    ).join(\n",
    "        baselines, on='hour', rsuffix='_baseline'\n",
    "    ).assign(\n",
    "        too_many_users=lambda x: x.username_baseline \\\n",
    "            * pcts.get('username', 1) <= x.username,\n",
    "        too_many_attempts=lambda x: x.attempts_baseline \\\n",
    "            * pcts.get('attempts', 1) <= x.attempts,\n",
    "        high_failure_rate=lambda x: x.failure_rate_baseline \\\n",
    "            * pcts.get('failure_rate', 1) <= x.failure_rate\n",
    "    ).query(\n",
    "        'too_many_users and too_many_attempts and high_failure_rate'\n",
    "    ).source_ip.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many IP addresses get flagged for being 25% greater than the mean baselines for distinct usernames, number of attempts, and failure rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_from_mean_ips = pct_change_threshold(\n",
    "    hourly_ip_logs, averages, \n",
    "    {key: 1.25 for key in ['username', 'attempts', 'failure_rate']}\n",
    ")\n",
    "pct_from_mean_ips.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tukey Fence\n",
    "Another strategy is to use the upper bound of the Tukey fence. The multiplier on the IQR is a parameter we will want to tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tukey_fence_test(trimmed_data, logs, k, pct=None):\n",
    "    \"\"\"\n",
    "    See which IP addresses get flagged with a Tukey fence with\n",
    "    multiplier k and optional percent differences.\n",
    "    \n",
    "    Parameters: \n",
    "        - trimmed_data: The data to use to calculate the baselines\n",
    "        - logs: The data to test\n",
    "        - k: The multiplier for the IQR\n",
    "        - pct: Dictionary of percentages per column for use with `pct_change_threshold()`\n",
    "        \n",
    "    Returns:\n",
    "        `pandas.Series` of flagged IP addresses\n",
    "    \"\"\"\n",
    "    q3 = get_baselines(trimmed_data, 'quantile', .75).drop(columns=['hour'])\n",
    "    q1 = get_baselines(trimmed_data, 'quantile', .25).drop(columns=['hour'])\n",
    "    iqr = q3 - q1\n",
    "    upper_bound = (q3 + k * iqr).reset_index()\n",
    "    return pct_change_threshold(logs, upper_bound, pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what gets flagged using the Tukey fence upper bound using a multiplier of 3 for the IQR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey_fence_ips = tukey_fence_test(\n",
    "    trimmed_hourly_logs, hourly_ip_logs, k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We once again use `nunique()` to see the number of items flagged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tukey_fence_ips.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-score\n",
    "We can use the Z-score to flag values beyond a certain number of standard deviations above the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score_test(trimmed_data, logs, cutoff):\n",
    "    \"\"\"\n",
    "    See which IP addresses get flagged with a Z-score greater than\n",
    "    or equal to a cutoff value.\n",
    "    \n",
    "    Parameters: \n",
    "        - trimmed_data: The data to use to calculate the baselines\n",
    "        - logs: The data to test\n",
    "        - cutoff: Flag row when z_score >= cutoff\n",
    "        \n",
    "    Returns:\n",
    "        `pandas.Series` of flagged IP addresses\n",
    "    \"\"\"\n",
    "    std_dev = get_baselines(trimmed_data, 'std').drop(columns=['hour'])\n",
    "    averages = get_baselines(trimmed_data, 'mean').drop(columns=['hour'])\n",
    "\n",
    "    return logs.assign(\n",
    "        hour=lambda x: x.datetime.dt.hour\n",
    "    ).join(\n",
    "        std_dev.join(\n",
    "            averages, \n",
    "            lsuffix='_std', \n",
    "            rsuffix='_mean'\n",
    "        ),\n",
    "        on='hour'\n",
    "    ).assign(\n",
    "        too_many_users=lambda x: \\\n",
    "            (x.username - x.username_mean) / x.username_std >= cutoff,\n",
    "        too_many_attempts=lambda x: \\\n",
    "            (x.attempts - x.attempts_mean) / x.attempts_std >= cutoff,\n",
    "        high_failure_rate=lambda x: \\\n",
    "            (x.failure_rate - x.failure_rate_mean) / x.failure_rate_std >= cutoff\n",
    "    ).query(\n",
    "        'too_many_users and too_many_attempts and high_failure_rate'\n",
    "    ).source_ip.drop_duplicates()\n",
    "\n",
    "z_score_ips = z_score_test(trimmed_hourly_logs, hourly_ip_logs, 3)\n",
    "z_score_ips.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Methods\n",
    "This is a classification problem with 4 outcomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_aids import ml_viz\n",
    "_ = ml_viz.confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a function to calculate the metrics of the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(alerted_ips, attack_ips, log_ips):\n",
    "    \"\"\"\n",
    "    Calculate true positives (TP), false positives (FP), \n",
    "    true negatives (TN), and false negatives (FN) for \n",
    "    IP addresses flagged as suspicious.\n",
    "    \n",
    "    Parameters:\n",
    "        - alerted_ips: `pandas.Series` of flagged IP addresses\n",
    "        - attack_ips: `pandas.Series` of attacker IP addresses\n",
    "        - log_ips: `pandas.Series` of all IP addresses seen\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of form (TP, FP, TN, FN)\n",
    "    \"\"\"\n",
    "    tp = alerted_ips.isin(attack_ips).sum()\n",
    "    tn = np.invert(np.isin(log_ips[~log_ips.isin(alerted_ips)].unique(), attack_ips)).sum()\n",
    "    fp = np.invert(alerted_ips.isin(attack_ips)).sum()\n",
    "    fn = np.invert(attack_ips.isin(alerted_ips)).sum()\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using, partials we can reduce our typing later by providing the arguments only once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this easier to call\n",
    "from functools import partial\n",
    "scores = partial(evaluate, attack_ips=attacks.source_ip, log_ips=pivot.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percent Difference from Mean\n",
    "Let's see how well the percent difference from the mean method did. Using our partial, we get all the components of the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, fp, tn, fn = scores(pct_from_mean_ips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these to calculate the **false positive rate (FPR)** or the false alarm rate:\n",
    "\n",
    "$$ FPR = \\frac{FP}{FP + TN} $$ \n",
    "\n",
    "and the **false discovery rate (FDR)** or the percentage of our alarms that are wrong:\n",
    "\n",
    "$$ FDR = \\frac{FP}{FP + TP} $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr, fdr\n",
    "fp / (fp + tn), fp / (fp + tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look into false negatives, we can calculate the **false negative rate (FNR)** or the miss rate:\n",
    "\n",
    "$$ FNR = \\frac{FN}{FN + TP} $$\n",
    "\n",
    "and the **false omission rate (FOR)**:\n",
    "\n",
    "$$ FOR = \\frac{FN}{FN + TN} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnr, for\n",
    "fn / (fn + tp), fn / (fn + tn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to calculate all of this for us, so we can compare the methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_stats(tp, fp, tn, fn):\n",
    "    \"\"\"Calculate metrics\"\"\"\n",
    "    return {\n",
    "        'FPR': fp / (fp + tn),\n",
    "        'FDR': fp / (fp + tp),\n",
    "        'FNR': fn / (fn + tp),\n",
    "        'FOR': fn / (fn + tn)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percent difference from the mean using trimmed baselines performs well all around:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_stats(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percent Difference from the Median\n",
    "We don't need to use the trimmed data here because the median is robust to outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = get_baselines(hourly_ip_logs, 'median')\n",
    "pct_from_median_ips = pct_change_threshold(\n",
    "    hourly_ip_logs, medians, \n",
    "    {key: 1.25 for key in ['username', 'attempts', 'failure_rate']}\n",
    ")\n",
    "tp, fp, tn, fn = scores(pct_from_median_ips)\n",
    "classification_stats(tp, fp, tn, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Methods\n",
    "We can use a `DataFrame` object to easily compare the methods we tried. All perform well, which one we use in practice will depend on the cost of false negatives vs. false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    method: classification_stats(*scores(ips))\n",
    "    for method, ips in {\n",
    "        'means': pct_from_mean_ips,\n",
    "        'medians': pct_from_median_ips,\n",
    "        'Tukey fence': tukey_fence_ips,\n",
    "        'Z-scores': z_score_ips\n",
    "    }.items()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div style=\"overflow: hidden; margin-bottom: 10px;\">\n",
    "    <div style=\"float: left;\">\n",
    "         <a href=\"../lab_12/financial_analysis.ipynb\">\n",
    "            <button>&#8592; Lab 12</button>\n",
    "        </a>\n",
    "    </div>\n",
    "    <div style=\"float: right;\">\n",
    "        <a href=\"../../solutions/lab_13/solutions.ipynb\">\n",
    "            <button>Solutions</button>\n",
    "        </a>\n",
    "        <a href=\"../ch_09/red_wine.ipynb\">\n",
    "            <button>Lab 9 &#8594;</button>\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
