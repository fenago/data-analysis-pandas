{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `partial_fit()` with grid search\n",
    "`GridSearchCV` doesn't have a `partial_fit()` method, but we can use `GridSearchCV` to find the best initial hyperparameters for our models before moving to `partial_fit()`.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "with sqlite3.connect('../../ch_11/logs/logs.db') as conn:\n",
    "    logs_2018 = pd.read_sql(\n",
    "        'SELECT * FROM logs WHERE datetime BETWEEN \"2018-01-01\" AND \"2019-01-01\";', \n",
    "        conn, parse_dates=['datetime'], index_col='datetime'\n",
    "    )\n",
    "    hackers_2018 = pd.read_sql(\n",
    "        'SELECT * FROM attacks WHERE start BETWEEN \"2018-01-01\" AND \"2019-01-01\";', \n",
    "        conn, parse_dates=['start', 'end']\n",
    "    ).assign(\n",
    "        duration=lambda x: x.end - x.start, \n",
    "        start_floor=lambda x: x.start.dt.floor('min'),\n",
    "        end_ceil=lambda x: x.end.dt.ceil('min')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X(log, day):\n",
    "    \"\"\"\n",
    "    Get data we can use for the X\n",
    "    \n",
    "    Parameters:\n",
    "        - log: The logs dataframe\n",
    "        - day: A day or single value we can use as a datetime index slice\n",
    "    \n",
    "    Returns: \n",
    "        A `pandas.DataFrame` object\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(log.loc[day].assign(\n",
    "        failures=lambda x: 1 - x.success\n",
    "    ).query('failures > 0').resample('1min').agg(\n",
    "        {'username': 'nunique', 'failures': 'sum'}\n",
    "    ).dropna().rename(\n",
    "        columns={'username': 'usernames_with_failures'}\n",
    "    ).assign(\n",
    "        day_of_week=lambda x: x.index.dayofweek, \n",
    "        hour=lambda x: x.index.hour\n",
    "    ).drop(columns=['failures']), columns=['day_of_week', 'hour'])\n",
    "\n",
    "def get_y(datetimes, hackers, resolution='1min'):\n",
    "    \"\"\"\n",
    "    Get data we can use for the y (whether or not a hacker attempted a log in during that time).\n",
    "    \n",
    "    Parameters:\n",
    "        - datetimes: The datetimes to check for hackers\n",
    "        - hackers: The dataframe indicating when the attacks started and stopped\n",
    "        - resolution: The granularity of the datetime. Default is 1 minute.\n",
    "        \n",
    "    Returns:\n",
    "        `pandas.Series` of Booleans.\n",
    "    \"\"\"\n",
    "    date_ranges = hackers.apply(\n",
    "        lambda x: pd.date_range(x.start_floor, x.end_ceil, freq=resolution), \n",
    "        axis=1\n",
    "    )\n",
    "    dates = pd.Series(dtype='object')\n",
    "    for date_range in date_ranges:\n",
    "        dates = pd.concat([dates, date_range.to_series()])\n",
    "    return datetimes.isin(dates)\n",
    "\n",
    "def get_X_y(log, day, hackers):\n",
    "    \"\"\"\n",
    "    Get the X, y data to build a model with.\n",
    "    \n",
    "    Parameters:\n",
    "        - log: The logs dataframe\n",
    "        - day: A day or single value we can use as a datetime index slice\n",
    "        - hackers: The dataframe indicating when the attacks started and stopped\n",
    "        \n",
    "    Returns:\n",
    "        X, y tuple where X is a `pandas.DataFrame` object\n",
    "        and y is a `pandas.Series` object\n",
    "    \"\"\"\n",
    "    X = get_X(log, day)\n",
    "    y = get_y(X.reset_index().datetime, hackers)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate January and February 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_jan, y_jan = get_X_y(logs_2018, '2018-01', hackers_2018)\n",
    "X_feb, y_feb = get_X_y(logs_2018, '2018-02', hackers_2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Run `GridSearchCV` to build a Passive Aggressive Classifier\n",
    "Train on January 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ml_utils.partial_fit_pipeline import PartialFitPipeline\n",
    "\n",
    "pipeline = PartialFitPipeline([\n",
    "    ('scale', StandardScaler()), \n",
    "    ('pa', PassiveAggressiveClassifier(random_state=0, max_iter=1000, tol=1e-3))\n",
    "])\n",
    "\n",
    "search_space = {\n",
    "    'pa__C': [0.01, 0.1, 1, 10],\n",
    "    'pa__fit_intercept': [True, False],\n",
    "    'pa__class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "pa_grid = GridSearchCV(pipeline, search_space, cv=5, scoring='f1_macro').fit(X_jan, y_jan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the best parameters after the grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model's initial performance (on February)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pa_grid.predict(X_feb)\n",
    "pd.Series(preds).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_feb, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import confusion_matrix_visual\n",
    "\n",
    "confusion_matrix_visual(y_feb, preds, class_labels=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Store the best estimator for `partial_fit()` usage later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa = pa_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Update the model with the February 2018 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa.partial_fit(X_feb, y_feb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate model on March through June 2018 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mar, y_mar = get_X_y(logs_2018, '2018-03', hackers_2018)\n",
    "X_q2, y_q2 = get_X_y(logs_2018, '2018-Q2', hackers_2018)\n",
    "X_eval = pd.concat([X_mar, X_q2])\n",
    "y_eval = pd.concat([y_mar, y_q2])\n",
    "preds = pa.predict(X_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get metrics on the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_eval, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import confusion_matrix_visual\n",
    "\n",
    "confusion_matrix_visual(y_eval, preds, class_labels=[False, True])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
