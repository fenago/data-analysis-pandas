{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions\n",
    "Simulation results will be different unless you use the seed. Check that your strategy for completing the exercises is similar to the sample solutions here, in that case.\n",
    "\n",
    "## Exercise 1\n",
    "Simulate December 2018 using the seed of 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../../lab_13/simulate.py \\\n",
    "    -s 27 \\\n",
    "    -u ../../lab_13/user_data/user_base.txt \\\n",
    "    -i ../../lab_13/user_data/user_ips.json \\\n",
    "    -l dec_2018_log.csv \\\n",
    "    -hl dec_2018_attacks.csv \\\n",
    "    31 \"2018-12-01\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports for Remaining Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "Find the number of unique usernames, attempts, successes, failures, and success/failure rates per IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_log = pd.read_csv('dec_2018_log.csv', parse_dates=True, index_col='datetime')\n",
    "\n",
    "log_aggs = dec_log.assign(\n",
    "    failures=lambda x: np.invert(x.success)\n",
    ").groupby('source_ip').agg(\n",
    "    {'username': 'nunique', 'success': 'sum', 'failures': 'sum'}\n",
    ").assign(\n",
    "    attempts=lambda x: x.success + x.failures,\n",
    "    success_rate=lambda x: x.success / x.attempts,\n",
    "    failure_rate=lambda x: 1 - x.success_rate\n",
    ").dropna().reset_index()\n",
    "\n",
    "log_aggs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "Create two subplots with failures versus attempts on the left and failure rate versus distinct usernames on the right. Draw a decision boundary for what you see. Be sure to color by whether or not it is a hacker IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_attack_ip = log_aggs.source_ip.isin(\n",
    "    pd.read_csv('dec_2018_attacks.csv').source_ip\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "for ax, (x, y) in zip(axes, (('attempts', 'failures'), ('username', 'failure_rate'))):\n",
    "    ax = sns.scatterplot(\n",
    "        x=log_aggs[x], \n",
    "        y=log_aggs[y], \n",
    "        hue=is_attack_ip,\n",
    "        ax=ax\n",
    "    )\n",
    "    ax.set_title(f'{y.title()} vs. {x.title()}')\n",
    "\n",
    "# boundaries\n",
    "axes[0].plot([0, 80], [80, 0], 'r--')\n",
    "axes[1].axhline(0.5, color='red', linestyle='--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "Build a rule-based criteria using percent difference from the median that flags an IP address if failures and attempts are 5 times the median OR if distinct usernames is 5 times the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_ip_logs = dec_log.assign(\n",
    "    failures=lambda x: np.invert(x.success)\n",
    ").groupby('source_ip').resample('1H').agg(\n",
    "    {'username': 'nunique', 'success': 'sum', 'failures': 'sum'}\n",
    ").assign(\n",
    "    attempts=lambda x: x.success + x.failures,\n",
    "    success_rate=lambda x: x.success / x.attempts,\n",
    "    failure_rate=lambda x: 1 - x.success_rate\n",
    ").dropna().reset_index()\n",
    "\n",
    "hourly_ip_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function from lab for getting baselines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_baselines(hourly_ip_logs, func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate hourly bootstrapped statistic per column.\n",
    "    \n",
    "    Parameters:\n",
    "        - hourly_ip_logs: Data to sample from.\n",
    "        - func: Statistic to calculate.\n",
    "        - args: Additional positional arguments for `func`\n",
    "        - kwargs: Additional keyword arguments for `func`\n",
    "    \n",
    "    Returns:\n",
    "        `pandas.DataFrame` of hourly bootstrapped statistics\n",
    "    \"\"\"\n",
    "    if isinstance(func, str):\n",
    "        func = getattr(pd.DataFrame, func)\n",
    "\n",
    "    return hourly_ip_logs.assign(\n",
    "        hour=lambda x: x.datetime.dt.hour\n",
    "    ).groupby('hour').apply(\n",
    "        lambda x: x.sample(10, random_state=0, replace=True).pipe(func, *args, **kwargs, numeric_only=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medians = get_baselines(hourly_ip_logs, 'median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flag if both failures and attempts are 5 times higher than the median or if usernames tried is 5 times higher than the median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_ips = hourly_ip_logs.assign(\n",
    "    hour=lambda x: x.datetime.dt.hour\n",
    ").join(\n",
    "    medians, on='hour', rsuffix='_median'\n",
    ").assign(\n",
    "    flag_median=lambda x: np.logical_or(\n",
    "        np.logical_and(\n",
    "            x.failures_median * 5 <= x.failures,\n",
    "            x.attempts_median * 5 <= x.attempts\n",
    "        ), x.username_median * 5 <= x.username\n",
    "    )\n",
    ").query('flag_median').source_ip.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "Calculate metrics to evaluate how well the ensemble method performed. We can use the `evaluate()` function from the lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(alerted_ips, attack_ips, log_ips):\n",
    "    \"\"\"\n",
    "    Calculate true positives (TP), false positives (FP), \n",
    "    true negatives (TN), and false negatives (FN) for \n",
    "    IP addresses flagged as suspicious.\n",
    "    \n",
    "    Parameters:\n",
    "        - alerted_ips: `pandas.Series` of flagged IP addresses\n",
    "        - attack_ips: `pandas.Series` of attacker IP addresses\n",
    "        - log_ips: `pandas.Series` of all IP addresses seen\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of form (TP, FP, TN, FN)\n",
    "    \"\"\"\n",
    "    tp = alerted_ips.isin(attack_ips).sum()\n",
    "    tn = np.invert(np.isin(log_ips[~log_ips.isin(alerted_ips)].unique(), attack_ips)).sum()\n",
    "    fp = np.invert(\n",
    "        np.isin(log_ips[log_ips.isin(alerted_ips)].unique(), attack_ips)\n",
    "    ).sum()\n",
    "    fn = np.invert(\n",
    "        np.isin(log_ips[log_ips.isin(attack_ips)].unique(), alerted_ips)\n",
    "    ).sum()\n",
    "    return tp, fp, tn, fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make a partial to store the attacker IP addreses and the unique IP addresses in the logs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make this easier to call\n",
    "from functools import partial\n",
    "scores = partial(\n",
    "    evaluate, \n",
    "    attack_ips=pd.read_csv('dec_2018_attacks.csv').source_ip, \n",
    "    log_ips=dec_log.source_ip.drop_duplicates()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the performance with the `classification_stats()` function from the lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_stats(tp, fp, tn, fn):\n",
    "    \"\"\"Calculate metrics\"\"\"\n",
    "    return {\n",
    "        'FPR': fp / (fp + tn),\n",
    "        'FDR': fp / (fp + tp),\n",
    "        'FNR': fn / (fn + tp),\n",
    "        'FOR': fn / (fn + tn)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance is decent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_stats(*scores(flagged_ips))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
