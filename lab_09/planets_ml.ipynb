{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing out-of-this world data\n",
    "Using data collected from the Open Exoplanet Catalogue database: https://github.com/OpenExoplanetCatalogue/open_exoplanet_catalogue/\n",
    "\n",
    "## Data License\n",
    "Copyright (C) 2012 Hanno Rein\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this database and associated scripts (the \"Database\"), to deal in the Database without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Database, and to permit persons to whom the Database is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Database. A reference to the Database shall be included in all scientific publications that make use of the Database.\n",
    "\n",
    "THE DATABASE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE DATABASE OR THE USE OR OTHER DEALINGS IN THE DATABASE.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets = pd.read_csv('data/planets.csv')\n",
    "planets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for correlated features\n",
    "It's important to perform an in-depth exploration of the data before modeling. This includes consulting domain experts, looking for correlations between variables, examining distributions, etc. The visualizations covered in chapters 5 and 6 will prove indispensible for this process. One such visualization is the heatmap which we can use to look for correlated features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "sns.heatmap(\n",
    "    planets.drop(columns='discoveryyear').corr(), \n",
    "    center=0, vmin=-1, vmax=1, square=True, annot=True,\n",
    "    cbar_kws={'shrink': 0.8}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Orbit shape\n",
    "| Eccentricity | Orbit Shape |\n",
    "| :---: | :---: |\n",
    "| 0 | Circular |\n",
    "| (0, 1) | Elliptical |\n",
    "| 1 | Parabolic |\n",
    "| > 1 | Hyperbolic |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.eccentricity.min(), planets.eccentricity.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the planets in the data have circular or elliptical orbits. Let's see the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets.eccentricity.hist()\n",
    "plt.xlabel('eccentricity')\n",
    "plt.ylabel('frequency')\n",
    "plt.title('Orbit Eccentricities')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the semi-major axis\n",
    "An ellipse, being an elongated circle, has 2 axes: **major** and **minor** for the longest and smallest ones, respectively. The *semi*-major axis is half the major axis. When compared to a circle, the axes are like the diameter crossing the entire shape and the semis are akin to the radius being half the diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_aids import misc_viz\n",
    "misc_viz.elliptical_orbit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking data values\n",
    "With just the variables of interest, we have a lot of missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets[['period', 'eccentricity', 'semimajoraxis', 'mass']].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we drop it, we are left with about 30% of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets[['period', 'eccentricity', 'semimajoraxis', 'mass']].dropna().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `describe()` to get a summary of the variables of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets[['period', 'eccentricity', 'semimajoraxis', 'mass']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Year and Orbit Length\n",
    "We have information on the planet list each planet belongs to. We may be wondering: are these planets are controversial because they are so far away?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    x=planets.semimajoraxis, y=planets.period,\n",
    "    hue=planets.list, alpha=0.5\n",
    ")\n",
    "plt.title('period vs. semimajoraxis')\n",
    "plt.legend(title='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since semi-major axis is highly correlated with period, let's see how the planets compare and label those in our solar system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "in_solar_system = (planets.list == 'Solar System').rename('in solar system?')\n",
    "sns.scatterplot(\n",
    "    x=planets.semimajoraxis, \n",
    "    y=planets.period, \n",
    "    hue=in_solar_system,\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_yscale('log')\n",
    "solar_system = planets[planets.list == 'Solar System']\n",
    "for planet in solar_system.name:\n",
    "    data = solar_system.query(f'name == \"{planet}\"')\n",
    "    ax.annotate(\n",
    "        planet, \n",
    "        (data.semimajoraxis, data.period), \n",
    "        (7 + data.semimajoraxis, data.period),\n",
    "        arrowprops=dict(arrowstyle='->')\n",
    "    )\n",
    "ax.set_title('log(orbital period) vs. semi-major axis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Similar Planets with k-Means Clustering\n",
    "Since we want to perform clustering to learn more about the data, we will build our pipeline standardizing the data before running k-means and fit it on the all the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "kmeans_pipeline = Pipeline([\n",
    "    ('scale', StandardScaler()), \n",
    "    ('kmeans', KMeans(8, random_state=0))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the data and fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_data = planets[['semimajoraxis', 'period']].dropna()\n",
    "kmeans_pipeline.fit(kmeans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can recreate our plot from before and this time, color by the cluster k-means put each planet in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "sns.scatterplot(\n",
    "    x=kmeans_data.semimajoraxis, \n",
    "    y=kmeans_data.period, \n",
    "    hue=kmeans_pipeline.predict(kmeans_data),\n",
    "    ax=ax, palette='Accent'\n",
    ")\n",
    "ax.set_yscale('log')\n",
    "solar_system = planets[planets.list == 'Solar System']\n",
    "for planet in solar_system.name:\n",
    "    data = solar_system.query(f'name == \"{planet}\"')\n",
    "    ax.annotate(\n",
    "        planet, \n",
    "        (data.semimajoraxis, data.period), \n",
    "        (7 + data.semimajoraxis, data.period),\n",
    "        arrowprops=dict(arrowstyle='->')\n",
    "    )\n",
    "ax.get_legend().remove()\n",
    "ax.set_title('KMeans Clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elbow point method can be used to pick a good value for `k`. This value will be were we begin to see diminishing returns in the reduction of the value of the objective function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.elbow_point import elbow_point\n",
    "\n",
    "ax = elbow_point(\n",
    "    kmeans_data, \n",
    "    Pipeline([\n",
    "        ('scale', StandardScaler()), \n",
    "        ('kmeans', KMeans(random_state=0))\n",
    "    ])\n",
    ")\n",
    "ax.annotate(\n",
    "    'possible appropriate values for k', xy=(2, 900), xytext=(2.5, 1500), \n",
    "    arrowprops=dict(arrowstyle='->')\n",
    ")\n",
    "ax.annotate(\n",
    "    '', xy=(3, 480), xytext=(4.4, 1450), arrowprops=dict(arrowstyle='->')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-means with the \"optimal\" k of 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pipeline_2 = Pipeline([\n",
    "    ('scale', StandardScaler()), \n",
    "    ('kmeans', KMeans(2, random_state=0))\n",
    "]).fit(kmeans_data)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "sns.scatterplot(\n",
    "    x=kmeans_data.semimajoraxis, \n",
    "    y=kmeans_data.period, \n",
    "    hue=kmeans_pipeline_2.predict(kmeans_data),\n",
    "    ax=ax\n",
    ")\n",
    "ax.set_yscale('log')\n",
    "solar_system = planets[planets.list == 'Solar System']\n",
    "for planet in solar_system.name:\n",
    "    data = solar_system.query(f'name == \"{planet}\"')\n",
    "    ax.annotate(\n",
    "        planet, \n",
    "        (data.semimajoraxis, data.period), \n",
    "        (7 + data.semimajoraxis, data.period),\n",
    "        arrowprops=dict(arrowstyle='->')\n",
    "    )\n",
    "ax.get_legend().remove()\n",
    "ax.set_title('KMeans Clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the cluster space\n",
    "Since we standardized the data, looking at the centers tells us the second cluster contains \"outliers\" for period and semi-major axis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_pipeline_2.named_steps['kmeans'].cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the clusters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up layout\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "outside = fig.add_axes([0.1, 0.1, 0.9, 0.9])\n",
    "inside = fig.add_axes([0.6, 0.2, 0.35, 0.35])\n",
    "\n",
    "# scaled data and cluster distance data\n",
    "scaled = kmeans_pipeline_2.named_steps['scale']\\\n",
    "    .fit_transform(kmeans_data)\n",
    "cluster_distances = kmeans_pipeline_2\\\n",
    "    .fit_transform(kmeans_data)\n",
    "\n",
    "for ax, data, title, axes_labels in zip(\n",
    "    [outside, inside], [scaled, cluster_distances],  \n",
    "    ['Visualizing Clusters', 'Cluster Distance Space'], \n",
    "    ['standardized', 'distance to centroid']\n",
    "):\n",
    "    sns.scatterplot(\n",
    "        x=data[:,0], y=data[:,1], ax=ax, alpha=0.75, s=100,\n",
    "        hue=kmeans_pipeline_2.named_steps['kmeans'].labels_\n",
    "    )\n",
    "\n",
    "    ax.get_legend().remove()\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(f'semimajoraxis ({axes_labels})')\n",
    "    ax.set_ylabel(f'period ({axes_labels})')\n",
    "    ax.set_ylim(-1, None)\n",
    "    \n",
    "# add the centroids to the outside plot\n",
    "cluster_centers = kmeans_pipeline_2.named_steps['kmeans'].cluster_centers_\n",
    "for color, centroid in zip(['blue', 'orange'], cluster_centers):\n",
    "    outside.plot(*centroid, color=color, marker='x')\n",
    "    outside.annotate(\n",
    "        f'{color} center', xy=centroid, xytext=centroid + [0, 5], \n",
    "        arrowprops=dict(arrowstyle='->')\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on the `scikit-learn` API\n",
    "\n",
    "|Method|Action|Used when...|\n",
    "|---|---|---|\n",
    "|`fit()`|Train the model or preprocessor|Modeling, preprocessing|\n",
    "|`transform()`|Transform the data into the new space|Clustering, preprocessing|\n",
    "|`fit_transform()`|Run `fit()`, followed by `transform()`|Clustering, preprocessing|\n",
    "|`score()`|Evaluate the model using the default scoring method|Modeling|\n",
    "|`predict()`|Use model to predict output values for given inputs|Modeling|\n",
    "|`fit_predict()`|Run `fit()`, followed by `predict()`|Modeling|\n",
    "|`predict_proba()`|Like `predict()`, but returns the probability of belonging to each class|Classification|\n",
    "\n",
    "\n",
    "#### Evaluation of model\n",
    "There are many metrics to choose from, but since we don't know the true labels of our data, we can only use unsupervised ones. We will use a few different metrics to get a more well-rounded view of our performance:\n",
    "\n",
    "##### Silhouette Score\n",
    "- true labels not known\n",
    "- higher = better defined (more separated) clusters\n",
    "- -1 is worst, 1 is best, near 0 indicates overlapping clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "silhouette_score(kmeans_data, kmeans_pipeline.predict(kmeans_data)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Davies-Bouldin Score\n",
    "- true labels not known\n",
    "- ratio of within-cluster distances to between-cluster distances\n",
    "- zero is the best partition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "davies_bouldin_score(kmeans_data, kmeans_pipeline.predict(kmeans_data)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calinski and Harabasz Score\n",
    "- true labels not known\n",
    "- higher = better defined (more separated) clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score\n",
    "calinski_harabasz_score(kmeans_data, kmeans_pipeline.predict(kmeans_data)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Length of Year in Earth Days (Period)\n",
    "1. separate x and y data, dropping nulls\n",
    "2. create the training and testing sets\n",
    "3. train a linear regression model (no preprocessing since we want to interpret the coefficients)\n",
    "4. isolate the coefficients from the model\n",
    "5. evaluate the model\n",
    "\n",
    "Step 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = planets[\n",
    "    ['semimajoraxis', 'period', 'mass', 'eccentricity']\n",
    "].dropna()\n",
    "X = data[['semimajoraxis', 'mass', 'eccentricity']]\n",
    "y = data.period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "Step 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lm = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get equation\n",
    "Step 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get intercept\n",
    "lm.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get coefficients\n",
    "[(col, coef) for col, coef in zip(X_train.columns, lm.coef_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of model\n",
    "Step 5\n",
    "\n",
    "In order to evaluate our model's predictions against the actual values, we need to make predictions for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the predictions and actual values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(5, 3))\n",
    "axes.plot(X_test.semimajoraxis, y_test, 'ob', label='actuals', alpha=0.5)\n",
    "axes.plot(X_test.semimajoraxis, preds, 'or', label='predictions', alpha=0.5)\n",
    "axes.set(xlabel='semimajoraxis', ylabel='period')\n",
    "axes.legend()\n",
    "axes.set_title('Linear Regression Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between the predictions and the actual values tells us they trend together, but we need to look at other metrics to quantify the errors our model makes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(y_test, preds)[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Residuals\n",
    "Our residuals have no pattern (left subplot); however, the distribution has some negative skew, and the residuals aren't quite centered around zero (right subplot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.regression import plot_residuals\n",
    "\n",
    "plot_residuals(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R<sup>2</sup>\n",
    "By default, the `score()` method of the `LinearRegression` object will give us the $R^2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not, we can use the `r2_score()` function from `sklearn.metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adjusted R<sup>2</sup>\n",
    "$R^2$ increases when we add regressors whether or not they actually improve the model. Adjusted $R^2$ penalizes additional regressors to address this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.regression import adjusted_r2\n",
    "adjusted_r2(lm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems with R<sup>2</sup>\n",
    "$R^2$ doesn't tell us about the prediction errors or if we specified the model correctly. Consider Anscombe's quartet from chapter 1:\n",
    "\n",
    "##### Anscombe's Quartet\n",
    "All four data sets have the same summary statistics (mean, standard deviation, correlation coefficient), despite having different data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anscombe = sns.load_dataset('anscombe').groupby('dataset')\n",
    "anscombe.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When fitted with a regression line, they all have the same $R^2$ despite some of them not indicating a linear relationship between x and y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_aids import stats_viz\n",
    "stats_viz.anscombes_quartet(r_squared=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explained Variance\n",
    "The percentage of the variance in the data is explained by our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import explained_variance_score\n",
    "explained_variance_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (MAE)\n",
    "This gives us an idea of how far off our predictions are on average (in Earth days):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root Mean Squared Error (RMSE)\n",
    "We can use this to punish large errors more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median Absolute Error\n",
    "We can also look at the median absolute error to ignore any outliers in prediction errors and get a better picture of our error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error\n",
    "median_absolute_error(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div style=\"overflow: hidden; margin-bottom: 10px;\">\n",
    "    <div style=\"float: left;\">\n",
    "        <a href=\"../../ch_08/anomaly_detection.ipynb\">\n",
    "            <button>&#8592; Chapter 8</button>\n",
    "        </a>\n",
    "        <a href=\"./planet_data_collection.ipynb\">\n",
    "            <button>Planet Data Collection</button>\n",
    "        </a>\n",
    "        <a href=\"./preprocessing.ipynb\">\n",
    "            <button>Preprocessing</button>\n",
    "        </a>\n",
    "        <a href=\"./red_wine.ipynb\">\n",
    "            <button>Red Wine</button>\n",
    "        </a>\n",
    "        <a href=\"./wine.ipynb\">\n",
    "            <button>Red + White Wine</button>\n",
    "        </a>\n",
    "    </div>\n",
    "    <div style=\"float: right;\">\n",
    "        <a href=\"../../solutions/ch_09/exercise_1.ipynb\">\n",
    "            <button>Solutions</button>\n",
    "        </a>\n",
    "        <a href=\"../ch_10/red_wine.ipynb\">\n",
    "            <button>Chapter 10 &#8594;</button>\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
