{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification by Wine Type\n",
    "\n",
    "## Wine Data\n",
    "Data from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "\n",
    "### Citations\n",
    "<pre>\n",
    "Dua, D. and Karra Taniskidou, E. (2017). \n",
    "UCI Machine Learning Repository [http://archive.ics.uci.edu/ml/index.php]. \n",
    "Irvine, CA: University of California, School of Information and Computer Science.\n",
    "</pre>\n",
    "\n",
    "<pre>\n",
    "P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "Modeling wine preferences by data mining from physicochemical properties.\n",
    "In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n",
    "</pre>\n",
    "\n",
    "Available at:\n",
    "- [@Elsevier](http://dx.doi.org/10.1016/j.dss.2009.05.016)\n",
    "- [Pre-press (pdf)](http://www3.dsi.uminho.pt/pcortez/winequality09.pdf)\n",
    "- [bib](http://www3.dsi.uminho.pt/pcortez/dss09.bib)\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine = pd.read_csv('data/winequality-red.csv')\n",
    "white_wine = pd.read_csv('data/winequality-white.csv', sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at quality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_quality_scores(df, kind):\n",
    "    ax = df.quality.value_counts().sort_index().plot.barh(\n",
    "        title=f'{kind.title()} Wine Quality Scores', figsize=(12, 3)\n",
    "    )\n",
    "    ax.axes.invert_yaxis()\n",
    "    for bar in ax.patches:\n",
    "        ax.text(\n",
    "            bar.get_width(), \n",
    "            bar.get_y() + bar.get_height()/2, \n",
    "            f'{bar.get_width()/df.shape[0]:.1%}',\n",
    "            verticalalignment='center'\n",
    "        )\n",
    "    plt.xlabel('count of wines')\n",
    "    plt.ylabel('quality score')\n",
    "\n",
    "    for spine in ['top', 'right']:\n",
    "        ax.spines[spine].set_visible(False)\n",
    "\n",
    "    return ax\n",
    "\n",
    "plot_quality_scores(white_wine, 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_quality_scores(red_wine, 'red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining red and white wine data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.concat([\n",
    "    white_wine.assign(kind='white'), red_wine.assign(kind='red')\n",
    "])\n",
    "wine.sample(5, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No null data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have more whites than reds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.kind.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to understand if chemical properties can be used to determine wine type. Unfortunately, `describe()` gives a very long output, so we need a visualization to compare the wines this way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine.drop(columns='quality').groupby('kind').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do chemical properties of the wine correlate to each other and the wine type?\n",
    "It's important to perform an in-depth exploration of the data before modeling. This includes consulting domain experts, looking for correlations between variables, examining distributions, etc. The visualizations covered in chapters 5 and 6 will prove indispensible for this process. One such visualization is the heatmap. In order to predict if the wine is red or white, we would look for correlations between chemical properties and wine type. We would also try to see if there is a difference in the distribution of our variables for white versus red wines. Some other helpful plot types include box plots, pair plots, and the scatter matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "sns.heatmap(\n",
    "    wine.drop(columns='quality').assign(\n",
    "        is_red=lambda x: np.where(x.kind == 'red', 1, 0)\n",
    "    ).corr(), \n",
    "    cbar_kws={'shrink': 0.8},\n",
    "    center=0, vmin=-1, vmax=1,\n",
    "    square=True, annot=True, fmt='.1g'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Red and White Wines by Their Chemical Properties\n",
    "This visualization will be easier to digest than the output of `describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "chemical_properties = [col for col in wine.columns if col not in ['quality', 'kind']]\n",
    "melted = wine.drop(columns='quality').melt(id_vars=['kind'])\n",
    "\n",
    "fig, axes = plt.subplots(math.ceil(len(chemical_properties) / 4), 4, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for prop, ax in zip(chemical_properties, axes):\n",
    "    sns.boxplot(\n",
    "        data=melted[melted.variable.isin([prop])], \n",
    "        x='variable', y='value', hue='kind', ax=ax\n",
    "    ).set_xlabel('')\n",
    "    \n",
    "# remove the extra subplots\n",
    "for ax in axes[len(chemical_properties):]:\n",
    "    ax.remove()\n",
    "\n",
    "plt.suptitle('Comparing Chemical Properties of Red and White Wines')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Red and White Wines\n",
    "1. separate x and y\n",
    "2. get the training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1\n",
    "wine_y = np.where(wine.kind == 'red', 1, 0)\n",
    "wine_X = wine.drop(columns=['quality', 'kind'])\n",
    "\n",
    "# 2\n",
    "w_X_train, w_X_test, w_y_train, w_y_test = train_test_split(\n",
    "    wine_X, wine_y, test_size=0.25, random_state=0, stratify=wine_y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. build a pipeline with standard scaler followed by logistic regression and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "white_or_red = Pipeline([\n",
    "    ('scale', StandardScaler()), \n",
    "    ('lr', LogisticRegression(random_state=0))\n",
    "]).fit(w_X_train, w_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kind_preds = white_or_red.predict(w_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. evaluate predictions\n",
    "\n",
    "We can use a confusion matrix to see how the model's predictions align with the actual class labels. The model only made 13 incorrect predictions; we will look into these in chapter 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import confusion_matrix_visual\n",
    "\n",
    "confusion_matrix_visual(w_y_test, kind_preds, ['white', 'red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision, recall, and $F_1$ score all look good with this model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(w_y_test, kind_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to use the confusion matrix is with sensitivity and specificity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visual_aids import ml_viz\n",
    "ml_viz.portion_of_confusion_matrix_considered({'sensitivity', 'specificity'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity-specificity plots plot sensitivity (TPR) versus 1-specificity (FPR) and are another way to evaluate performance. They include all sections of the confusion matrix, which is why in cases of class balance, they are optimistic of performance. These plots are also called ROC curves.\n",
    "\n",
    "### ROC Curves\n",
    "Visualize model performance using true positive rates and false positive rates. The area under the curve is in the range [0, 1] with 1 being the best. This visualization allows us to compare our model to the baseline of random guessing (the diagonal line with AUC of 0.5), as well as, other models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_viz.roc_curve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model performs very well, the area under the curve (AUC) is nearly 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import plot_roc\n",
    "\n",
    "plot_roc(w_y_test, white_or_red.predict_proba(w_X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall curves\n",
    "When faced with class imbalance, we use precision-recall curves since ROC curves will be optimistic of model performance. AP is the weighted average precision and AUC is the area under the curve once again in the range [0, 1]. The baseline is now the percentage of observations belonging to the positive class. Values below this line are worse than random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_utils.classification import plot_pr_curve\n",
    "\n",
    "plot_pr_curve(w_y_test, white_or_red.predict_proba(w_X_test)[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<div style=\"overflow: hidden; margin-bottom: 10px;\">\n",
    "    <div style=\"float: left;\">\n",
    "        <a href=\"../../ch_08/anomaly_detection.ipynb\">\n",
    "            <button>&#8592; Chapter 8</button>\n",
    "        </a>\n",
    "        <a href=\"./preprocessing.ipynb\">\n",
    "            <button>Preprocessing</button>\n",
    "        </a>\n",
    "        <a href=\"./planets_ml.ipynb\">\n",
    "            <button>Planets</button>\n",
    "        </a>\n",
    "        <a href=\"./red_wine.ipynb\">\n",
    "            <button>Red Wine</button>\n",
    "        </a>\n",
    "    </div>\n",
    "    <div style=\"float: right;\">\n",
    "        <a href=\"../../solutions/ch_09/exercise_1.ipynb\">\n",
    "            <button>Solutions</button>\n",
    "        </a>\n",
    "        <a href=\"../ch_10/red_wine.ipynb\">\n",
    "            <button>Chapter 10 &#8594;</button>\n",
    "        </a>\n",
    "    </div>\n",
    "</div>\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
